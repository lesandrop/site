
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="">
<head>

<script type="text/javascript">
    (function(c,l,a,r,i,t,y){
        c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
        t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
        y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
    })(window, document, "clarity", "script", "ppda8aahae");
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PS6CQ7DZZD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PS6CQ7DZZD');
</script>


  <meta charset="utf-8" />
  <meta name="description" content="Notas de aula com a dinâmica de Debate Estruturado conduzidos em disciplinas de Interação Humano-Computador">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Aulas de IHC com Debates Estruturados</title>
  <!-- Favicon -->   
 <link href="../../img/lesandro-ponciano-icon.png" rel="shortcut icon"/>
  
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../../css/bootstrap.min.css" />
  <link rel="stylesheet" href="../../css/style.css" />
  <link rel="stylesheet" href="../../css/font-awesome.min.css"/>
  <link rel="stylesheet" href="../../css/pandoc.css" />
        
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8152535423798932"
       crossorigin="anonymous"></script>
	
</head>
<body>


<!-- Header section start -->
<header class="header-section">
   <div class="container-fluid">
      <div class="row">	
	    <div class="col-md-4">
		   <div class="text-md-right">
               <a href="../../index.html">Home</a> > <a href="../index.html">Teaching</a> > <a href="index.html">IHC</a> > Debate Estruturado
           </div>
        </div>
     </div>
   </div>
</header>


<div class="content">

<h1>Aulas de IHC com Debates Estruturados</h1>
<p>O debate estruturado é estratégia didático-pedagógica aplicada no ensino e aprendizagem de Interação Humano-Computador (IHC). Aqui estão reunidos notas de debates conduzidos pelo Prof <strong>Lesandro Ponciano</strong> <a href="https://orcid.org/0000-0002-5724-0094" aria-label="View ORCID record"> <img src="../../img/ORCID-iD_icon_24x24.png" alt="ORCID iD"/></a>. Para mais informações sobre a estratégia de Debate Estruturado, veja o artigo <a href="https://doi.org/10.5753/ihc.2018.4209">Debate Estruturado: Uma Estratégia Pedagógica para Ensino e Aprendizagem de Valores Humanos em Interação Humano-Computador<a>.</p>

<div id="indice">
    <h2>Índice de Debates</h2>
    <ul>
      <li><a href="#designs-obscuros">Designs obscuros: usuários como dependentes e designers como obscurantistas da sociedade?</a></li>
      <li><a href="#modelo-privacidade-explicabilidade">Modelos de usuários e seus requisitos: atendendo as necessidades de privacidade e explicabilidade</a></li>
      <li><a href="#explicar-ia">Como explicar ao usuário o comportamento da inteligência artificial que é parte de um software?</a></li>
    </ul>
  </div>

<div>
  <a name="designs-obscuros"></a><h2>Designs obscuros: usuários como dependentes e designers como obscurantistas da sociedade?</h2>

  <h3>Textos de referência para o debate</h3>
  <ol>
  <li> <a href="https://doi.org/10.1016/j.chb.2018.12.022">Examination of smartphone dependence: Functionally and existentially dependent behavior on the smartphone</a>
  <li>  <a href="https://iris.polito.it/retrieve/e384c434-b2c3-d4b2-e053-9f05fe0a1d67/dpimpact.pdf">Towards Understanding the Dark Patterns That Steal Our Attention </a>
  </ol>

  <h3>Questões colocadas durante o debate</h3>
  <ul>
    <li>A dependência funcional pode ser explicada/justificada por um viés de utilidade. Mas e a dependência existencial? Em que medida o problema pode estar associado ao dispositivo e em que medida o problema pode estar associado à pessoa que faz uso dele? Qual o papel do designer nesse contexto?</li>
    <li>O mundo físico está se digitalizando e os dispositivos estão se tornando a porta de acesso a esse mundo digital. O que se busca ao restringir o acesso da criança a esse mundo no qual os adultos estão tão imersos? Em que medida o risco que se evita foi criado pelo designer se valer de dark patterns nos sistemas que projeta?</li>
    <li>Quando a dependência se torna um problema ou um vício? Pode-se falar em uma "linha vermelha" no comportamento do usuário? Se sim, qual o papel do designer em garantir que essa linha não seja ultrapassada pelo usuário? Fazer tecnologias que causam vício ou dependência pode ser um objetivo para o designer? Por que?</li>
    <li>Poucas pessoas vão brigar com uma criança se ela ficar o dia todo lendo um livro, mas vão brigar se ela ficar o dia todo no smartphone/tablet. Já há quem associa o uso de sistemas digitais a maior risco do que benefício. Os designers, ao empregarem dark patterns, são obscurantistas da sociedade e estão estigmatizando os sistemas digitais?</li>
  </ul>
</div>
<hr>

<div>
 <a name="modelo-privacidade-explicabilidade"></a><h2>Modelos de usuários e seus requisitos: atendendo as necessidades de privacidade e explicabilidade</h2>

<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://arxiv.org/pdf/1708.05905"> Designing for pragmatists and fundamentalists: Privacy concerns and attitudes on the internet of things</a>
<li>  <a href="https://arxiv.org/pdf/2108.04640"> Modeling and evaluating personas with software explainability requirements</a>
</ol>

<h3>Questões colocadas durante o debate</h3>

<ul>
<li>Qual é o real desafio de se gerar modelos dos usuários? Por que essa tarefa é desafiadora para designers? Por que é necessário, por exemplo, empregar técnicas de modelagem de usuários como "mapa de empatia" para gerar personas? Qual a importância de instrumentos como o Persona Perception Scale nesse contexto?</li>
<li>Podemos projetar sistemas que proponham uma barganha com o usuário? Ou seja, um sistema solicite ao usuário informações privadas para, em troca, lhe prover produtos e serviços? Como seria um acordo entre os dois? Seria um acordo justo?</li>
</li>Há um clássico fenômeno chamado paradoxo de privacidade (privacy paradox) que diz que as pessoas tendem a falar que se preocupam muito com privacidade, mas geralmente, tendem a exibir atitudes de quem não se preocupa com privacidade. Por que isso ocorre? Quais efeitos negativos  isso pode ter sob o design de sistemas?</li>
<li> Pode haver conflito entre explicabilidade e privacidade? Ao se projetar sistemas que tenham explicabilidade há o risco de que o sistema viole a privacidade dos usuários ao prover uma explicação? Exemplifique por que isso ocorre ou não.</li>
</ul>
</div>

<div>
 <a name="explicar-ia"></a><h2>Como explicar ao usuário o comportamento da inteligência artificial que é parte de um software?</h2>

<h3>Textos de referência para o debate</h3>
<ol>
<li><a href="https://dl.acm.org/doi/abs/10.1145/3424953.3426545">Exploring user profiles based on their explainability requirements in interactive systems.</a></li>
<li><a href="https://revistas.pucsp.br/index.php/galaxia/article/view/41614/31634">Algoritmos racistas: a hiper-ritualização da solidão da mulher negra em bancos de imagens digitais</a></li>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1566253519308103">Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI.</a></li>
</ol>

<h3>Questões colocadas durante o debate</h3>
<ul> 
<li>A explicabilidade não está presente em muitos sistemas por que é difícil implementá-la. Já é difícil implementar um software que usa algoritmos complexos, fazer com que esse software seja capaz de se auto explicar torna seu desenvolvimento diversas vezes mais difícil. Como lidar com isso? Se for uma imposição legal, como LGPD, o que fazer?</li>
<li> Diante da necessidade de tirar benefício dos serviços providos pelo sistema, as pessoas estão preocupadas com se tal sistema implementa ou não explicabilidade? Certamente, as pessoas estão interessadas em que o software seja fácil de usar, mas elas estão interessadas em saber como eles são implementados? Por que estariam?  Por que não estariam?</li>
<li> Racismo e misoginia são exemplos de comportamentos que podem se manifestar em softwares. É seguro enquanto indivíduo e enquanto sociedade se basear fortemente em software que não enquanto usuários e, algumas vezes, enquanto desenvolvedores não sabemos como funcionam? Quando o problema é do software e quando o problema é dos dados que o software usa? </li>
<li> Dos conceitos associados à explicabilidade, um dos mais destacados é a transparência, que está relacionada  à  inteligibilidade  dos  mecanismos  internos  do  sistema, qual o desafio de fazer softwares transparentes? Como dar visibilidade aos processos internos do software? Fazer um software transparente é o suficiente para lidar com problemas como misoginia e racismo?</li>
<li> De forma geral, usuários de sistemas computacionais temem mais que sua privacidade seja invadida por outros usuários do sistema do que pelo sistema em si ou por terceiros? Por que é assim?</li>
</ul>
</div>

	
</div>
	<!-- Footer section start -->
	<footer class="footer-section">
		<div class="container text-center">
			<div class="copyright">
                 The source code of this page is available at https://github.com/lesandrop
			</div>
		</div>
	</footer>
	<!-- Footer section end -->
</body>
</html>
