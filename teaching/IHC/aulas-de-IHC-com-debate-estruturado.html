
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="">
<head>

<script type="text/javascript">
    (function(c,l,a,r,i,t,y){
        c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
        t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
        y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
    })(window, document, "clarity", "script", "ppda8aahae");
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PS6CQ7DZZD"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PS6CQ7DZZD');
</script>


  <meta charset="utf-8" />
  <meta name="description" content="Notas de aulas da disciplina de Interação Humano-Computador conduzidas com a dinâmica de Debate Estruturado">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Aulas de IHC com Debates Estruturados</title>
  <!-- Favicon -->   
 <link href="../../img/lesandro-ponciano-icon.png" rel="shortcut icon"/>
  
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../../css/bootstrap.min.css" />
  <link rel="stylesheet" href="../../css/style.css" />
  <link rel="stylesheet" href="../../css/font-awesome.min.css"/>
  <link rel="stylesheet" href="../../css/pandoc.css" />
        
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8152535423798932"
       crossorigin="anonymous"></script>
	
</head>
<body>


<!-- Header section start -->
<header class="header-section">
   <div class="container-fluid">
      <div class="row">	
	    <div class="col-md-4">
		   <div class="text-md-right">
               <a href="../../index.html">Home</a> > <a href="../index.html">Teaching</a> > <a href="index.html">IHC</a> > Debate Estruturado
           </div>
        </div>
     </div>
   </div>
</header>


<div class="content">

<h1>Aulas de IHC com Debates Estruturados</h1>
<p>O <a href="https://doi.org/10.5753/ihc.2018.4209">Debate Estruturado</a> é estratégia didático-pedagógica aplicada no ensino e aprendizagem de Interação Humano-Computador (IHC) publicada em 2019 no Workshop sobre Educação em IHC (WEIHC) da Sociedade Brasileira de Computação. Os debates exploram como a tecnologia pode impactar valores humanos e abordam desafios e possibilidades no design e na interação com sistemas computacionais. Nesta página estão reunidas anotações de debates estruturados conduzidos pelo Prof. <strong>Lesandro Ponciano</strong> <a href="https://orcid.org/0000-0002-5724-0094" aria-label="View ORCID record"> <img src="../../img/ORCID-iD_icon_24x24.png" alt="ORCID iD"/></a> entre os anos de 2019 e 2024. Para mais informações sobre a estratégia de Debate Estruturado, veja o artigo científico <em><a href="https://doi.org/10.5753/ihc.2018.4209">Debate Estruturado: Uma Estratégia Pedagógica para Ensino e Aprendizagem de Valores Humanos em Interação Humano-Computador</a></em>.</p>

<div id="indice">
    <h2>Índice de Debates Estruturados</h2>
    <ol>
      <li><a href="#ia-ihc">Impacto da Inteligência Artificial na Interação Humano-Computador</a></li>
      <li><a href="#podcasting-plataformas-aprendizagem">Plataformas, podcasting e aprendizagem</a></li>
      <li><a href="#alertas-mudancas-climaticas">Notificações em tempos de mudanças climáticas: avisando e alertando por meio sistemas computacionais</a></li>
      <li><a href="#designs-obscuros">Designs obscuros: usuários como dependentes e designers como obscurantistas da sociedade?</a></li>
      <li><a href="#comunicacao-clima-plataforma">Comunicação e interação via plataformas computacionais no contexto das mudanças climáticas</a></li>
      <li><a href="#cores-fontes-formas">Cores, fontes, formas e a percepção humana do design de Websites</a></li>
      <li><a href="#modelo-privacidade-explicabilidade">Modelos de usuários e seus requisitos: atendendo as necessidades de privacidade e explicabilidade</a></li>
      <li><a href="#explicar-ia">Como explicar ao usuário o comportamento da inteligência artificial que é parte de um software?</a></li>
      <li><a href="#face-genero-privacidade">Face, Gênero e Privacidade em Software Interativo</a></li>
      <li><a href="#auto-representacao-digital">Características, Riscos e Utilidades da auto-representação digital</a></li>
      <li><a href="#cognicao-sistemas">Cognição em e por meio de sistemas interativos: pessoas e sistemas</a></li>
      <li><a href="#jogos-inclusao-segregacao">Efeitos do projeto de jogos eletrônicos e suas comunidades na inclusão e segregação</a></li>
      <li><a href="#questao-genero">Dependência em computadores móveis: tablets e smartphones</a></li>	  
      <li><a href="#dependencia-smartphones">Questão de Gênero em Software Interativo </a></li>	  
      <li><a href="#ihc-software-usuario">Interação Humano-Computador em software desenvolvido por usuários finais</a></li>	  	    
      <li><a href="#legado-digital">Legado digital: interação e imortalidade</a></li>
      <li><a href="#bci-ihc">Relações entre Interação Humano-Computador e Interface Cérebro-Computador</a></li>
      <li><a href="#bots-ihc">Interagindo com robôs e por meio de robôs</a></li>
      <li><a href="#individualidade-diversidade-persona">Considerando Individualidade e Diversidade em sistemas sociotécnicos</a></li>
    </ol>
  </div>
	
<hr>
 <div>
  <a name="ia-ihc"></a><h2>Impacto da Inteligência Artificial na Interação Humano-Computador</h2>
  <h3>Data do Debate: Maio/2025</h3>
  <h3>Textos de referência para o debate</h3>
  <ol>
  <li> <a href="https://doi.org/10.1145/3712068">Augmenting Human Potential: The Role of LLMs in Shaping the Future of HCI</a>
  <li> <a href="https://doi.org/10.1108/ITP-07-2022-0519">Artificial Intelligence (AI) and User Experience (UX) design: A systematic literature review and future research agenda</a>
  </ol>
  <h3>Questões colocadas durante o debate</h3>
  <ul>
    <li>Quanto ao uso de sistemas interativos pela sociedade, de forma geral, pode-se dizer que IA é mocinho ou vilão para a sociedade? Por exemplo, seu papel mais determinante está em aumentar a acessibilidade de sistemas ou de isolar as pessoas, sendo cada vez mais atendidas por uma IA em vez de uma pessoa? A forma que as pessoas têm usado IA as tornam pessoas mais inteligentes (augmenting human potential) ou atrofia a inteligência delas? As pessoas estão se tornando meros usuários de ferramentas que tudo fazem?</li>
    <li>No que se refere a tarefas associadas a IHC, de forma geral, pode-se dizer que LLM é aliada ou oponente? Sistemas com IA embutidas estão vindo para aumentar a produtividade das pessoas ou substituí-las? É notável que várias tarefas tipicamente associadas a IHC, como produção de artes gráficas e implementação de front-end, já estão em grande parte substituídas por IA. Seria isso um auxílio para o designer ou uma substituição dele?</li>
    <li>Para que se possa falar de "co-criação" humano-IA, é preciso que ambos tenham habilidades e potencialidades diferentes que possam se complementar. Quais são as habilidades exclusivas dos designers e quais são as habilidades exclusivas das IAs. Como os dois podem conseguir fazer juntos o que nenhum deles sozinho conseguiria fazer? Em quais situações reais essa "co-criação" teria emprego válido?</li>
    <li>Como a IA pode ser uma aliada na avaliação de sistemas interativos? Quais os riscos de chegarmos ao contexto de que termos IAs que implementam e também avaliam a qualidade de experiência dos sistemas que fizeram? Há algo essencial que muda nos sistemas feitos por IA e que afetaria significativamente os métodos de avaliação atuais? Devemos passar a avaliar coisas diferentes?</li>
  </ul>
</div>
	
<hr>
 <div>
  <a name="podcasting-plataformas-aprendizagem"></a><h2>Plataformas, podcasting e aprendizagem</h2>
  <h3>Data do Debate: Maio/2025</h3>
  <h3>Textos de referência para o debate</h3>
  <ol>
  <li> <a href="https://doi.org/10.1177/2056305119880002">The Platforms of Podcasting: Past and Present</a>
  <li> <a href="https://doi.org/10.1177/08920206124380">Utilising podcasts for learning and teaching: a review and ways forward for e-Learning cultures</a>
  </ol>
  <h3>Questões colocadas durante o debate</h3>
  <ul>
    <li>Das primeiras abordagens de podcast do início do século até os sofisticados sistemas atuais, como plataformas afetam a proliferação de conteúdo de podcast? Seria a distribuição feita pela plataforma mais determinante do tamanho da audiência do que a qualidade do conteúdo do podcast em si?</li>
    <li>Da perspectiva do estudante, de que forma o engajamento na elaboração do podcast pode fomentar a aprendizagem para além da aprendizagem de cultura digital? Essa tarefa associada ao podcast coloca o estudante diante de desafios cognitivos que o levem a aprendizagem significa? De que forma estética típica de podcast se associa aprendizagem? Ou não se associa? Porque?</li>
    <li>Por que atualmente se difunde a ideia atual de que podcast está associado a conteúdo de baixa qualidade? Entrevistas sem conteúdo, com perguntas pouco racionais e sem contexto para vida do participante… Qual o perigo de se associar "aprendizagem" em um contexto em que vigora o "entretenimento"? Seria isso uma confusão do que é diversão e comunicação com o que é educação e didática?</li>
    <li>De que forma plataformas como Itunes, Youtube e SoundCloud se tornaram gatekeepers para podcasting? Elas estão influenciando a natureza do debate online? O que exatamente se busca regras como as da Amazon de que podcast não podem ter conteúdo irrelevante ou spam, conteúdo que possa ser interpretado como racista, misógino ou homofóbico, palavrões ou violência no título, na descrição, na arte ou nos episódios, etc</li>
  </ul>
</div>
<hr>

	
<div>
  <a name="alertas-mudancas-climaticas"></a><h2>Notificações em tempos de mudanças climáticas: avisando e alertando por meio sistemas computacionais</h2>
  <h3>Data do Debate: Abril/2025</h3>
  <h3>Textos de referência para o debate</h3>
  <ol>
  <li> <a href="https://doi.org/10.1016/j.ijdrr.2018.02.033">Towards user-orientated weather warnings</a>
  <li> <a href="https://doi.org/10.1061/NHREFO.NHENG-1721">An Experimental Study of Message Strategies for Mobile Alerts and Warnings</a>
  </ol>
  <h3>Questões colocadas durante o debate</h3>
  <ul>
    <li>Usuário podem perder a confiança nos avisos (warnings) em razão de falsos positivos (cry-wolf-syndrome), avisos (warnings) de eventos que acabam não ocorrendo. Como evitar isso? Não é mais danoso deixar de emitir um aviso e eventualmente o desastre ocorrer (falso negativo)? Pode estar a autoridade emitindo a informação para se eximir de uma responsabilização caso seja acusado de não ter avisado a população? Quais as implicações?</li>
    <li>Estratégias de mensagem instrumental, empática e de escolha antecipada produziram níveis comparáveis ​​de eficácia de segurança em casos que os participantes relataram níveis mais altos de eficácia da mensagem (ou seja, disposição de autoproteção). A conclusão desse resultado não seria que, para pessoas que estão dispostas a agir, pouco importa o formato da mensagem? O design de mensagens é mais desafiador para pessoas que são mais resistentes? Por exemplo, que não querem sair de uma área de risco? Por quê?</li>
    <li>Muito se questiona sobre consistência, qualidade e valor dos avisos (warnings) gerados pelas autoridades públicas, mas o que dizer da combinação desses avisos com outros acessados pelos usuários? Por exemplo, aplicativos de instalação padrão em computadores  e smartphone (mobile alert technologies) notificam o usuário sobre o tempo e clima. Como lidar com essas várias fontes? Há o risco de gerar mais confusão do que esclarecimento? Os vários formatos contribuem para a compreensibilidade dado que o usuário pode escolher qual lhe atende em termos de linguagem?</li>
    <li>Qual o limite da efetividade de avisos e alertas de informação em texto? Quando se pensa o contexto de cidades pequenas do interior, onde há altas taxas de analfabetismo, essa abordagem é efetiva? Quais seriam as alternativas? No caso das alternativas, os resultados qualitativos e quantitativos sobre a personalização do conteúdo da mensagem se manteriam ou mudariam? Por quê?</li>
  </ul>
</div>
<hr>
		
<div>
  <a name="designs-obscuros"></a><h2>Designs obscuros: usuários como dependentes e designers como obscurantistas da sociedade?</h2>
  <h3>Data do Debate: Novembro/2024</h3>
  <h3>Textos de referência para o debate</h3>
  <ol>
  <li> <a href="https://doi.org/10.1016/j.chb.2018.12.022">Examination of smartphone dependence: Functionally and existentially dependent behavior on the smartphone</a>
  <li>  <a href="https://iris.polito.it/retrieve/e384c434-b2c3-d4b2-e053-9f05fe0a1d67/dpimpact.pdf">Towards Understanding the Dark Patterns That Steal Our Attention </a>
  </ol>
  <h3>Questões colocadas durante o debate</h3>
  <ul>
    <li>A dependência funcional pode ser explicada/justificada por um viés de utilidade. Mas e a dependência existencial? Em que medida o problema pode estar associado ao dispositivo e em que medida o problema pode estar associado à pessoa que faz uso dele? Qual o papel do designer nesse contexto?</li>
    <li>O mundo físico está se digitalizando e os dispositivos estão se tornando a porta de acesso a esse mundo digital. O que se busca ao restringir o acesso da criança a esse mundo no qual os adultos estão tão imersos? Em que medida o risco que se evita foi criado pelo designer se valer de dark patterns nos sistemas que projeta?</li>
    <li>Quando a dependência se torna um problema ou um vício? Pode-se falar em uma "linha vermelha" no comportamento do usuário? Se sim, qual o papel do designer em garantir que essa linha não seja ultrapassada pelo usuário? Fazer tecnologias que causam vício ou dependência pode ser um objetivo para o designer? Por que?</li>
    <li>Poucas pessoas vão brigar com uma criança se ela ficar o dia todo lendo um livro, mas vão brigar se ela ficar o dia todo no smartphone/tablet. Já há quem associa o uso de sistemas digitais a maior risco do que benefício. Os designers, ao empregarem dark patterns, são obscurantistas da sociedade e estão estigmatizando os sistemas digitais?</li>
  </ul>
</div>
<hr>

<div>
 <a name="comunicacao-clima-plataforma"></a><h2>Comunicação e interação via plataformas computacionais no contexto das mudanças climáticas</h2>
<h3>Data do Debate: Novembro/2024</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://www.nature.com/articles/s44168-023-00080-3">How citizens engage with the social media presence of climate authorities: the case of five Brazilian cities</a>
<li>  <a href="https://journals.sagepub.com/doi/full/10.1177/1329878X211038004">Strategies for climate change communication through social media: Objectives, approach, and interaction</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>Quanto ao objetivo, comunicar a população sobre um risco eminente de evento climático (algo que ocorre no curto prazo) é algo essencialmente diferente de comunicar a população sobre "mudanças climáticas" em geral (algo que ocorre no longo prazo), dito isso, como conciliar no contexto de comunicação de risco as estratégias usadas na comunicação de mudanças climáticas?</li>
<li>Na preparação para eventos climáticos eminentes e na comunicação sobre mudança climática de forma geral, o engajamento da população na comunicação com as autoridades é baixo. As mídias sociais são uma plataforma adequada para essa comunicação ou a estratégia usada é inadequada? As mídias sociais são adequadas para discussão de um assunto tão sério? Se sim, como realizar essa comunicação? Se não, o que fazer?</li>
<li>Qual o papel que as plataformas de mídias sociais desempenham em intermediar o debate sobre preparação e adaptação para mudanças climáticas? De que forma as suas funcionalidades (re-postar, like, responder, emojis, hashtags, etc) podem fomentar ou inibir o debate? Dada a linguagem de mídias sociais, como devem as autoridades lidar com o fato de que pessoas respondem dizendo que informação postada por ela está errada?</li>
<li>Uma questão recorrente e comum aos dois artigos é o paralelo "one-way (single-loop) conversation" versus "two-way (double-loop) conversation", como conduzir "two-way conversation" por autoridades responsáveis por cidades com milhões de habitantes e que são seguidas por centenas de milhares de pessoas nas redes sociais? Ainda, em se tratando da iminência de um evento climático extremo, como alcançar um tempo de resposta às milhares de questões em tempo hábil de fazer alguma diferença?</li>
</ul>
</div>
<hr>

<div>
 <a name="cores-fontes-formas"></a><h2>Cores, fontes, formas e a percepção humana do design de Websites</h2>
<h3>Data do Debate: Setembro/2024</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://www.sciencedirect.com/science/article/pii/S0747563224000359">Users’ reactions to website designs: A neuroimaging study based on evolutionary psychology with a focus on color and button shape</a>
<li>  <a href="https://dl.acm.org/doi/abs/10.1145/3173574.3173911">A Case for Design Localization: Diversity of Website Designs in 44 Countries</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>Há 440 milhões de anos, os ascendentes dos seres humanos vivendo na savana não tinham linguagem e cultura minimamente desenvolvidos, mas iniciavam a percepção de cores como forma de sobrevivência, de que forma, milhões de anos depois, seus descendentes ao usar sites Web ainda podem estar se baseando na percepções de cores desenvolvidas naquela época?</li>
<li>Há diferenças em designs, designers e usuários em diferentes países. Se pessoas em países diferentes têm preferências diferentes em termos dos elementos de design de um site Web, a que se deve essa diferença? Os elementos que afetam a percepção e preferência dos usuários são os mesmos que afetam as decisões do designer dado que ambos são seres humanos?</li>
<li>Pode-se analisar o que o ser humano reporta (fala) sobre cores e formas e pode-se investigar cognitivamente como o ser humano reage a esses elementos em um website. Há correspondência entre o que se reporta e o que se observa cognitivamente? Por quê e quais as implicações para o design e avaliação de sistemas interativos?</li>
<li>Deve-se priorizar a homogeneização em detrimento da heterogeneização de designs de sites web buscando sua inserção em diferentes regiões geográficas? De que forma as características locais influenciam o design e de que forma os designs influenciam as características locais? Há risco de colonização por design?</li>
</ul>
</div>
<hr>
	
<div>
 <a name="modelo-privacidade-explicabilidade"></a><h2>Modelos de usuários e seus requisitos: atendendo as necessidades de privacidade e explicabilidade</h2>
<h3>Data do Debate: Setembro/2024</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://arxiv.org/pdf/1708.05905"> Designing for pragmatists and fundamentalists: Privacy concerns and attitudes on the internet of things</a>
<li>  <a href="https://arxiv.org/pdf/2108.04640"> Modeling and evaluating personas with software explainability requirements</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>Qual é o real desafio de se gerar modelos dos usuários? Por que essa tarefa é desafiadora para designers? Por que é necessário, por exemplo, empregar técnicas de modelagem de usuários como "mapa de empatia" para gerar personas? Qual a importância de instrumentos como o Persona Perception Scale nesse contexto?</li>
<li>Podemos projetar sistemas que proponham uma barganha com o usuário? Ou seja, um sistema solicite ao usuário informações privadas para, em troca, lhe prover produtos e serviços? Como seria um acordo entre os dois? Seria um acordo justo?</li>
</li>Há um clássico fenômeno chamado paradoxo de privacidade (privacy paradox) que diz que as pessoas tendem a falar que se preocupam muito com privacidade, mas geralmente, tendem a exibir atitudes de quem não se preocupa com privacidade. Por que isso ocorre? Quais efeitos negativos  isso pode ter sob o design de sistemas?</li>
<li> Pode haver conflito entre explicabilidade e privacidade? Ao se projetar sistemas que tenham explicabilidade há o risco de que o sistema viole a privacidade dos usuários ao prover uma explicação? Exemplifique por que isso ocorre ou não.</li>
</ul>
</div>
<hr>

<div>
 <a name="jogos-inclusao-segregacao"></a><h2>Efeitos do projeto de jogos eletrônicos e suas comunidades na inclusão e segregação</h2>
<h3>Data do Debate: Novembro/2023</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://www.sciencedirect.com/science/article/pii/S0747563223003072">Gender disparities in esports – An explanatory mixed-methods approach</a>
<li>  <a href="https://www.sciencedirect.com/science/article/pii/S0747563223002832">Belonging without being”: Relationships between problematic gaming, internet use, and social group attachment in adolescence </a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>Participantes, independentemente de gênero, reportam que determinada comunidade de jogos é tóxica e atribui isso à dificuldade dos membros de lidar com a "frustração", por exemplo, diante da derrota. Se a plataforma ou comunidade não inibir tais comportamentos tóxicos, quais os efeitos disso sobre quem tem esse comportamento e que é alvo dele?</li>
<li>A que se deve o comportamento tóxico de membros de comunidades de jogos? Seria a baixa maturidade (idade), o gênero, a anonimidade ou algo específico do modelo mental provocado pelo jogo ou pela comunidade? Por que esse comportamento se manifesta online mais do que offline?</li>
<li>Independentemente da ocorrência de comportamentos tóxicos, pode o uso excessivo de jogos ser um sintoma ou a causa da degradação de um senso pertencimento, afetando as relações sociais dos adolescentes? De que modo a vida social offline do adolescente pode ser prejudicada pelo uso excessivo de jogos?</li>
<li>O que é um "uso saudável de jogos online" e "uso saudável da internet" por adolescentes? O que tal uso precisaria ter para que possa ser classificado como "saudável" ou "seguro"? Seria necessário alguma distinção na forma de uso dependendo do gênero?</li>
</ul>
</div>
<hr>
	
<div>
<a name="explicar-ia"></a><h2>Como explicar ao usuário o comportamento da inteligência artificial que é parte de um software?</h2>
<h3>Data do Debate: Novembro/2021</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li><a href="https://dl.acm.org/doi/abs/10.1145/3424953.3426545">Exploring user profiles based on their explainability requirements in interactive systems.</a></li>
<li><a href="https://revistas.pucsp.br/index.php/galaxia/article/view/41614/31634">Algoritmos racistas: a hiper-ritualização da solidão da mulher negra em bancos de imagens digitais</a></li>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1566253519308103">Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI.</a></li>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul> 
<li>A explicabilidade não está presente em muitos sistemas por que é difícil implementá-la. Já é difícil implementar um software que usa algoritmos complexos, fazer com que esse software seja capaz de se auto explicar torna seu desenvolvimento diversas vezes mais difícil. Como lidar com isso? Se for uma imposição legal, como LGPD, o que fazer?</li>
<li> Diante da necessidade de tirar benefício dos serviços providos pelo sistema, as pessoas estão preocupadas com se tal sistema implementa ou não explicabilidade? Certamente, as pessoas estão interessadas em que o software seja fácil de usar, mas elas estão interessadas em saber como eles são implementados? Por que estariam?  Por que não estariam?</li>
<li> Racismo e misoginia são exemplos de comportamentos que podem se manifestar em softwares. É seguro enquanto indivíduo e enquanto sociedade se basear fortemente em software que não enquanto usuários e, algumas vezes, enquanto desenvolvedores não sabemos como funcionam? Quando o problema é do software e quando o problema é dos dados que o software usa? </li>
<li> Dos conceitos associados à explicabilidade, um dos mais destacados é a transparência, que está relacionada  à  inteligibilidade  dos  mecanismos  internos  do  sistema, qual o desafio de fazer softwares transparentes? Como dar visibilidade aos processos internos do software? Fazer um software transparente é o suficiente para lidar com problemas como misoginia e racismo?</li>
<li> De forma geral, usuários de sistemas computacionais temem mais que sua privacidade seja invadida por outros usuários do sistema do que pelo sistema em si ou por terceiros? Por que é assim?</li>
</ul>
</div>
<hr>
	
<div>
 <a name="face-genero-privacidade"></a><h2>Face, Gênero e Privacidade em Software Interativo</h2>
<h3>Data do Debate: Setembro/2021</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://www.sciencedirect.com/science/article/pii/S0747563221000285 ">“I don't want to be known for that:” The role of temporality in online self-presentation of young gay and bisexual males</a>
<li>  <a href="https://arxiv.org/pdf/1708.05905">Designing for pragmatists and fundamentalists: Privacy concerns and attitudes on the internet of things</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>A forma como as pessoas (ou sociedade)  conceituam as pessoas (ou a forma como ela reconhece e percebe as pessoas) muda do offline para o online? Questionar o gênero de alguém é algo inerente a apenas um desses contextos? Podem as redes sócias aumentar ou diminuir a ocorrência disso? Como os jovens GBM têm lidado com a rotulação?</li>
<li>Em que medida um comportamento de expressão em uma rede social de duplo significado é uma tentativa de mostrar personalidade ou provocar a dúvida? A semiótica da interação social de jovens GBM a partir dos recursos do Instagram é uma busca de se apresentar ou de construir uma face alternativa?</li>
<li>De forma geral, usuários de sistemas computacionais temem mais que sua privacidade seja invadida por outros usuários do sistema do que pelo sistema em si? Por que é assim?</li>
<li>"if they don't get a couple of likes within a minute, then I'll delete"... Como recursos de interfaces como contagens de likes e followers está influenciando o comportamento de jovens GBM? Em que medida eles podem estar buscando mais suporte nesses indicadores do que em pessoas próximas? Quais são os riscos?</li>
<li>Há um clássico fenômeno chamado paradoxo de privacidade (privacy paradox) que diz que as pessoas tendem a falar que se preocupam muito com privacidade, mas geralmente, tendem a exibir atitudes de quem não se preocupa com privacidade. Por que isso ocorre?</li>
<li>Podemos projetar sistemas que proponham uma barganha com o usuário? Ou seja, um sistema solicita ao usuário informações privadas para, em troca, lhe prover produtos e serviços? Como seria um acordo entre os dois, isso seria justo e correto?</li>
</ul>
</div>
<hr>

<div>
 <a name="cognicao-sistemas"></a><h2>Cognição em e por meio de sistemas interativos: pessoas e sistemas</h2>
<h3>Data do Debate: Setembro/2021</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://www.sciencedirect.com/science/article/pii/S0167739X17303618 ">Agreement-based credibility assessment and task replication in human computation systems</a>
<li>  <a href="https://sol.sbc.org.br/index.php/wei/article/view/27769">O papel do hábito de estudo no desempenho do aluno de programação</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>Em sistemas que se baseiam em respostas de várias pessoas para várias tarefas, qual a relação entre dificuldade da tarefa e consenso entre as pessoas? Quanto mais pessoas executarem a tarefa, melhor em termos se obter um resultado correto? Nesse contexto, qual a diferença da credibilidade para o voto majoritário?</li>
<li>Na perspectiva das pessoas, quanto mais tarefas forem executadas melhor em termos de aprendizagem que as pessoas têm? Aprendizagem é uma questão de quantidade ou de temporalidade? Qual o melhor hábito de execução de tarefas por estudantes que estão buscando se tornar especialistas na tarefa?</li>
<li>Qual domínio de tarefas computacionais que seres humanos são melhores para executar do que as máquinas? O que pode levar o ser humano a errar a execução de uma tarefa é diferente do que pode levar uma máquina a errar a execução? Quais os desafios de fazer sistemas interativos em que as pessoas atuam como "computadores"?</li>
<li>Como o ser humano faz (ou deveria fazer) para aprender algo e como as máquinas (são "ensinadas") a fazer algo? A forma como o ser humano aprende é diferente da forma como uma máquina "aprende"? Como é a relação de aprendizagem em sistemas que há cada vez mais humanos e máquinas realizando computação?</li>
</ul>
</div>
<hr>

<div>
<a name="bci-ihc"></a><h2>Relações entre Interação Humano-Computador e Interface Cérebro-Computador</h2>
<h3>Data do Debate: Abril/2021</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://www.sciencedirect.com/science/article/pii/S0925231216312152">Brain computer interface: control signals review</a>
<li> <a href="https://ieeexplore.ieee.org/document/8302482">Brain-Computer Interface Control in a Virtual Reality Environment and Applications for the Internet of Things</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>De que deriva o grande interesse por BCI a ponto de aumentar o número de grupos de pesquisa, empresas e países que estão avançando sobre essa área? Qual o potencial e desafio desse paradigma em relação à interação que hoje é feita principalmente por voz e toque? É apenas um item na interação multimodal?</li>
<li>Quais novos desafios de interface surgem na escolha de usar BCI invasiva ou não invasiva? A interface não invasiva é mais delimitadora? Se sim, de que forma? Quais problemas pontuados pela engenharia cognitiva podem estar presentes nesse tipo de interface?</li>
<li>Em que medida o canal do BCI é bidirecional e é unidirecional? Para o ser humano, trata-se do desenvolvimento de um novo sentido, da substituição de um sentido existente, ou de outra coisa? BCI é só interface ou também é interação? Por que?</li>
<li>A evolução do sistema computacional sempre gerou evolução no paradigma de interação. Em comparação aos paradigmas atuais, pode-se dizer que BCI é mais aderente aos sistemas computacionais emergentes, como aqueles baseados em computação ubíqua e internet das coisas? Por que?</li>
<li>Como deve ser a interface de sistemas computacionais para que pessoas possam interagir com os computadores por meio de BCI? Qual papel os paradigmas de interação atuais ainda podem desempenhar? BCI permite eliminar totalmente a travessia dos golfos da execução e avaliação?</li>
<li>O que muda na construção de sistemas interativos para que a interação possa ser feita via BCI? O que seria falar de eficácia, eficiência e satisfação nesse contexto? BCI se adequaria à perspectiva ferramenta, mídia, sistema ou parceiro do discurso ou outra coisa?</li>
</ul>
</div>
<hr>

<div>
<a name="ihc-software-usuario"></a><h2>Interação Humano-Computador em software desenvolvido por usuários finais</h2>
<h3>Data do Debate: Novembro/2020</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://doi.org/10.1145/3357155.3358463">CodeMaster UI design - app inventor: a rubric for the assessment of the interface design of Android apps developed with app inventor</a>
<li> <a href="https://doi.org/10.1145/3357155.3358460">Creating chatbots to talk with humans: HCI evaluations and perspectives</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>Muitos defendem que todas as pessoas precisam aprender "pensamento computacional", e, até mesmo, programação. Considerando que programar no nível de blocos visuais é usar um software A (como o App Inventor) para fazer fazer software B, qual o papel da interface e interação do software A no aprendizado e naquilo que se pode produzir?</li>
<li>Usuários finais (não conhecem de TI) conseguem programar um app dotado de Inteligência Artificial? Sendo possível, esse usuário entende realmente o que app dele faz? Não sendo possível, como avançar a programação por usuários na medida em que IA é cada vez mais usada em apps?</li>
<li>Softwares como o App Inventor podem ser efetivos na aprendizagem de pensamento computacional e programação, mas eles são efetivos para se ensinar IHC? Há recursos que permitam às pessoas perceberem que o app que está sendo produzido tem ou não atributos de usabilidade? Como isso é ou pode ser considerado nesse tipo de software?</li>
<li>Há diversos tipos de avaliação que podem ser conduzidas (observação, investigação e inspeção). Como o App inventor ajuda na avaliação de apps produzidos por meio dele? Além disso, eventuais problemas e vícios de usabilidade do App Inventor podem afetar a usabilidade do app feito por meio dele? Más práticas do App Inventor podem gerar más práticas nos Apps? Como lidar com isso?</li>
<li>Qual o papel que um componente de IA tem na usabilidade e comunicabilidade de um app? Se um app faz uso de um componentes que é uma IA e esse app apresenta baixa usabilidade, como saber se o problema é decorrente do app em si ou da IA que ele usa?</li>
<li>Muitas ferramentas estão buscando que usuários finais possam programar apps por componentes visuais e até mesmo usando IA. Há riscos em programar apps usando blocos que são "caixas pretas"? Quando ocorre um defeito como um bug, o usuário que programou saberá lidar com isso? As ferramentas apresentam recursos de depuração (debugging) que sejam acessíveis a usuários finais?</li>
</ul>
</div>
<hr>

<div>
 <a name="legado-digital"></a><h2>Legado digital: interação e imortalidade</h2>
<h3>Data do Debate: Setembro/2019</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://dl.acm.org/doi/abs/10.1145/3160504.3160580">The Acceptability of Digital Immortality: Today’s Human is Tomorrow’s Avatar”</a>
<li>  <a href="https://dl.acm.org/doi/10.1145/3160504.3160508">A Conceptual Framework to design Users Digital Legacy Management Systems</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li> Uma decisão de legado digital e do uso de informações pessoais após a morte está muitas vezes associada à visão da tecnologia e de seu potencial atual. Para o que isso pode evoluir se a tecnologia evoluir? O que se está realmente permitindo ou  autorizando?</li>
<li> Um “avatar” de alguém falecido é só um “avatar”? Na incapacidade de evoluir, pode-se ver a pessoa (ou seu “avatar”) torna-se obsoleto em relação ao tempo, de modo a não nos interessar mais. Na capacidade de evoluir, podemos nos decepcionar com a evolução perdendo afinidade. O que realmente se deseja?</li>
<li> Para quem morre, quando e por que faz sentido efetivamente se preocupar com os dados que deixa? Como o sistema deve ser para que essas “preocupações” sejam observadas? Quais garantias devem ser oferecidas?</li>
<li>Para quem vive, quando e por que faz sentido efetivamente se preocupar com os dados que recebe ou que deixa de receber? Quais responsabilidades devem estar associadas com os dados que se recebe? Como lidar com isso no sistema?</li>
</ul>
</div>
<hr>
	
<div>
<a name="dependencia-smartphones"></a><h2>Dependência em computadores móveis: tablets e smartphones</h2>
<h3>Data do Debate: Novembro/2019</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://doi.org/10.1016/j.chb.2018.12.043">“I cannot live without my [tablet]”: Children's experiences of using tablet technology within the home</a>
<li> <a href="https://doi.org/10.1016/j.chb.2018.12.022">Examination of smartphone dependence: Functionally and existentially dependent behavior on the smartphone</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>A dependência funcional pode ser explicada/justificada por um viés de utilidade. Mas e a dependência existencial? Em que medida o problema pode estar associado ao dispositivo e em que medida o problema pode estar associado à pessoa que faz uso dele? Qual o papel do designer nesse contexto?</li>
<li>Quando a dependência se torna um problema ou um vício? Pode-se falar em uma "linha vermelha" no comportamento do usuário? Se sim, qual o papel do designer em garantir que essa linha não será ultrapassada pelo usuário? Fazer tecnologias que causam vício ou dependência pode ser um objetivo para o designer?</li>
<li>O mundo físico está se digitalizando e que os dispositivos estão se tornando a porta de acesso a esse mundo digital. O que se busca ao restringir o acesso da criança a esse mundo no qual os adultos estão tão imersos? Qual é exatamente o risco que se evita? Como o designer pode ajudar a reduzir tais os riscos?</li>
<li>Qual é a balança do risco-benefício. Por exemplo, poucas pessoas vão brigar com uma criança se ela ficar o dia todo lendo um livro, mas vão brigar se ela ficar o dia todo no smartphone/tablet. Associa-se ao smartphone/tablet maior risco do que benefício? Por quê?  Qual o papel do designer em mudar esse cenário?</li>
</ul>
</div>
<hr>

<div>
<a name="questao-genero"></a><h2>Questão de Gênero em Software Interativo 
</h2>
<h3>Data do Debate: Novembro/2019</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://doi.org/10.5753/sbsc.2017.9963">Me sinto de mãos dadas! Um estudo sobre efeitos de comunidade no comportamento online de suas participantes</a>
<li> <a href="https://doi.org/10.5753/sbsc.2017.9968">Caracterização de Opressão de Gênero em Redes Sociais a partir de Violações dos Princípios de Afetibilidade: Um estudo de caso no Facebook</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>As desigualdades de gênero e suas opressões tão discutidas na sociedade atual estão se manifestando também em sistemas interativos (uso e projeto)? Ou, os sistemas interativos são neutros e igualitário?</li>
<li>O sistema permitir que as mulheres criem uma comunidade exclusiva para mulheres não seria uma forma de preconceito de gênero contra homens em vez de uma forma de superação do preconceito de gênero?</li>
<li>O designer de IHC deve desempenhar algum papel para evitar que sistemas interativos sejam opressores de gênero ou evitar que sistemas sejam usados para opressão de gênero? Se sim, qual? Se não, por quê?</li>
<li>No caso de sistemas que são “parceiros do discurso” e que empregam Inteligência Artificial, há o risco deles aprenderem a realizar opressão de gênero contra seus usuários. Como lidar com esse risco no design do sistema?</li>
</ul>
</div>
<hr>
	
<div>
 <a name="auto-representacao-digital"></a><h2>Características, Riscos e Utilidades da auto-representação digital</h2>
<h3>Data do Debate: Maio/2019</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://www.sciencedirect.com/science/article/pii/S0747563219303796">How do adolescents cope with cyberhate? Psychometric properties and socio-demographic differences of a coping with cyberhate scale</a>
<li>  <a href="https://www.sciencedirect.com/science/article/pii/S0747563219303711">Do you filter who you are?: Excessive self-presentation, social cues, and user evaluations of Instagram selfies</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>As pessoas revelam um pouco de como elas são (características psicológicas, culturais e de gênero) quando interagem com sistemas computacionais, definindo fotos, imagens, cores, palavras. Por exemplo, isso revela o quão extrovertida a pessoa é. Quais são os riscos disso para a pessoa? O que o designer pode fazer/implementar para mitigar esses riscos?</li>
<li>A visão do designer, sobre “quem você usuário é”/ "quer ou precisa fazer" no sistema, pode restringir não apenas as funcionalidades do sistema, mas também a forma como o usuário se expressa e cria uma identidade no sistema. Por exemplo, um sistema que força o usuário a colocar uma foto do rosto dela, não aceitando outra foto. Quais são os riscos disso para o usuário? O que o designer pode fazer/implementar para mitigar esses riscos</li>
<li>"As pessoas buscam por aparência nas redes sociais", "deixar uma impressão positiva", "mostrar que é atraente". Essas são manifestações do que as pessoas são? Ou, são manifestações do que o designer das redes sociais levam as pessoas a querem mostrar que são? Exemplo, os diversos filtros disponibilizados para fotos. O que as pessoas fazem com as redes sociais e o que as redes sociais fazem com as pessoas?</li>
<li>Transformar o conhecimento do comportamento humano em utilidade e diferencial competitivo (uso por empregadores, departamentos de RH) não é algo novo e é quase inevitável que ocorra no mundo digital. Mas quais são os riscos que isso traz para as pessoas e para o meio digital como um todo? O que o designer pode fazer/prover para ajudar as pessoas a mitigarem tais riscos?</li>
</ul>
</div>
<hr>

<div>
<a name="individualidade-diversidade-persona"></a><h2>Considerando Individualidade e Diversidade em sistemas sociotécnicos</h2>
<h3>Data do Debate: Novembro/2018</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://doi.org/10.1080/10447318.2021.1908670">A Survey of 15 Years of Data-Driven Persona Development </a>
<li> <a href="https://jonisalminen.com/wp-content/uploads/2024/07/Leveraging-Personas-for-Social-Impact-A-Review-of-Their-Applications-to-Social-Good-in-Design.pdf">Leveraging Personas for Social Impact: A Review of Their Applications to Social Good in Design</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>Como aproximar o projetista do modelo mental “do usuário” podendo ser “os usuários” tão diferentes entre si? Agregar e rotular não seria desrespeitar as individualidades?</li>
<li>Na Engenharia de Software já aceitamos que os requisitos mudam ao longo do tempo, também já aceitamos que os usuários mudam? Como criar personas que contenham informações realmente relevantes ao desenvolvimento do software?</li>
<li>Quais cuidados deve-se ter quando mapear as experiências de um usuário com uma aplicação nas experiências projetadas do usuário com outra aplicação? Não seria um reducionismo achar que o usuário “é assim” e “se comporta assim” em diversos sistemas?</li>
<li>Configurações de privacidade serem feitas por default baseado na persona que representa o usuário é uma ameaça ou é uma utilidade? Quais os riscos e os benefícios disso para a pessoa?</li>
</ul>
</div>
<hr>
	
<div>
<a name="bots-ihc"></a><h2>Interagindo com robôs e por meio de robôs</h2>
<h3>Data do Debate: Maio/2018</h3>
<h3>Textos de referência para o debate</h3>
<ol>
<li> <a href="https://doi.org/10.5210/fm.v21i11.7090">Social bots distort the 2016 U.S. Presidential election online discussion</a>
<li> <a href="https://doi.org/10.1109/TCSS.2021.3103515">Social Bots and Their Coordination During Online Campaigns: A Survey</a>
</ol>
<h3>Questões colocadas durante o debate</h3>
<ul>
<li>Felizmente fake news são checáveis, mas infelizmente nem tudo é. Quem usa sistemas computacionais, em alguns momentos, tem suas ações e comportamentos determinados por algoritmos, software, robôs. Em que medida as pessoas estão sendo controladas por eles e quais os riscos?</li>
<li>Muitos robôs tentam copiar o comportamento humano, mas ainda são apenas marionetes ou replicadores. Ainda assim, já trazem riscos. Quais novos riscos tendem a surgir quando tais robôs forem capazes de gerar sua própria identidade e seus próprios conteúdos?</li>
<li>Robôs interativos tentam se parecer com um ser humano em uma conversa. Se um robô tem acesso a dados e é capaz de realizar computações de forma muito mais rápida do que um ser humano é capaz de pensar, não estaria o ser humano em desvantagem nessa conversa? Há algum risco nisso?</li>
<li>Ao se projetar interface e interação, projetistas são muitas vezes norteados por preceitos éticos e morais. Na sua opinião, qual deveria ser o principal preceito ético e moral dos projetistas de robôs para redes sociais como Twitter? Ou um robô pode fazer qualquer coisa que ele for capaz de fazer?</li>
</ul>
</div>
<hr>


	
</div>
	<!-- Footer section start -->
	<footer class="footer-section">
		<div class="container text-center">
			<div class="copyright">
                 The source code of this page is available at https://github.com/lesandrop
			</div>
		</div>
	</footer>
	<!-- Footer section end -->
</body>
</html>
